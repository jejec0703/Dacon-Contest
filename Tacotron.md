Tacotron

- 2017년 구글에서 공개한 TTS모델

- Encoder - Decoder 구조 및 바다나우 Attention mechanism을 이용

- 입력으로 텍스트를 받아서 출력으로 스펙트로그램(음성을 숫자로 나타내는 하나의 방법) 자체를 생성한다.

  ==> 파라미터를 생성하는 다른 TTS 모델과 다른점!

- <text, audio> pair를 이용한 End-to-End 학습

  ==> 예로 텍스트로 '나는 학교에 간다'를 타코트론 모델에 넣으면 스펙트로그램으로 바로 생성되어 출력된다.

- 인코더 아웃풋의 linear sum을 통해서 만든 히든벡터(컨텍스트 벡터)와 GRU셀의 

아웃풋을 concat해서 디코더 아웃풋에 새로운 인풋으로 들어간다. 



[단계]

1. 음성 추출

   => 자동화 (google speech api, text similarity 이용)

   => 뉴스 / 유튭 / 오디오북 (50+시간 데이터)

   => acc : 0.9+  

2. 문장 별 자르기 

3. 텍스트 - 음성 맞추기

사용한 모델 - 'Tacotron' from google research

과거에는 텍스트 -> 음성 과정에서 토큰화 / 운율분석 / 검색 합성등 의 과정을 거쳤는데 타코트론은 저 파이프라인을 합쳐서 모델에 텍스트를 넣으면 바로 음성이 나올수 있도록 간편하게 함

타코트론 구성 모듈 4가지 - 인코더 / 디코더 / 어텐션 / 보코더

1. 인코더 <Embedding>
   1. 텍스트를 입력받아 정보를 잘 나타내는 숫자로 나오게 함

ex) ㅋ ㅏ ㄹ ㅡ ㅍ ㅔ [character embedding] : 글자 -> 숫자

=> 캐릭터 임베딩의 장점 : 새로운 단어가 들어왔을 때 자/모음 별로 쪼개서 임베딩되기 때문에 다른 단어 임베딩에서 각각 가져와서 합성할 수 있다.

2. 디코더 <Bidirectional-RNN>
   	1. 스펙트로그램을 만들기 위한 단계
    	2. <GO> -> pre-net -> attention -> rnn을 거쳐 n개의 스펙트로그램 예측 : 마지막 스펙트로그램이 다음 입력값 (반복)
    	3. 문장이 끝날 때까지 반복
    	4. n개 스펙트로그램들의 리스트를 얻을수있다.
3. 어텐션 <Attention>
   	1. 인코더에서 만들어진 텍스트 임베딩과 디코더를 합쳐준다.
    	2. 어텐션이란 ? 어디에 '집중' 할 것인지.
    	3. 한 문장에서 발생하는 공백값에서 쉼 
    	4. 일반화 : 학습하지 않았던 문장도 얼마나 잘 말할 수 있는가?
    	5. 어텐션이 잘 학습된 경우에 새로운 단어도, 띄어쓰기도 잘 말할 수 있음.
4. 보코더
   1. 스펙트로그램을 음성으로 만들어주는 알고리즘인 griffin-lim reconstruction을 거치면 드디어 음성이 나온다.



